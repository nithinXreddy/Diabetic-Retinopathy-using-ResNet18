# -*- coding: utf-8 -*-
"""DiabeticRetinopathy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PyPQ2YeupjnjQnEaqvxAUamyo3cHKH9G

## **CNN**
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# Commented out IPython magic to ensure Python compatibility.
!unzip /content/drive/MyDrive/archive69.zip
# %ls

import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory

IMG_SHAPE = (224, 224)
BATCH_SIZE = 32
TRAIN_DIR = "/content/train"
TEST_DIR = "/content/test"
VAL_DIR = "/content/valid"
train_data = image_dataset_from_directory(TRAIN_DIR,
                                          image_size = IMG_SHAPE,
                                          batch_size = BATCH_SIZE,
                                          label_mode = 'categorical')

test_data = image_dataset_from_directory(TEST_DIR,
                                          image_size = IMG_SHAPE,
                                          batch_size = BATCH_SIZE,
                                          label_mode = 'categorical')
validation_data = image_dataset_from_directory(VAL_DIR,
                                          image_size = IMG_SHAPE,
                                          batch_size = BATCH_SIZE,
                                          label_mode = 'categorical', shuffle = False)

img = plt.imread(TRAIN_DIR + "/DR/000c1434d8d7_png.rf.620970d7d209700b4cf09b8f36f52ff9.jpg")
plt.imshow(img)

from tensorflow.keras import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense, RandomWidth, RandomHeight, RandomRotation, RandomFlip, RandomZoom, Conv2D, MaxPool2D, Flatten

from tensorflow.keras.models import Sequential

inputs = Input(shape = IMG_SHAPE + (3, ))
x = Conv2D(128, 3, activation = 'relu')(inputs)
x = Conv2D(128, 3, activation = 'relu')(x)
x = MaxPool2D()(x)
x = Conv2D(64, 3, activation = 'relu')(x)
x = Conv2D(64, 3, activation = 'relu')(x)
x = MaxPool2D()(x)
x = Conv2D(32, 3, activation = 'relu')(x)
x = Conv2D(32, 3, activation = 'relu')(x)
x = MaxPool2D()(x)
x = Flatten()(x)
outputs = Dense(2, activation = 'sigmoid')(x)

model1 = Model(inputs, outputs)

model1.compile(loss = 'binary_crossentropy',
               optimizer = tf.keras.optimizers.Adam(),
               metrics = ['accuracy'])

model1.summary()

history1 = model1.fit(train_data, epochs = 4, validation_data = test_data)

model1.evaluate(validation_data)

from sklearn.metrics import classification_report

y_preds = model1.predict(validation_data).argmax(axis = 1)

y_labels = []

for images, labels in validation_data.unbatch():
  y_labels.append(labels.numpy().argmax())

print(classification_report(y_labels, y_preds))

inputs = Input(shape = IMG_SHAPE + (3, ))
x = Conv2D(128, 3, activation = 'relu')(inputs)
x = Conv2D(128, 3, activation = 'relu')(x)
x = MaxPool2D()(x)
x = Conv2D(64, 3, activation = 'relu')(x)
x = Conv2D(64, 3, activation = 'relu')(x)
x = Conv2D(32, 3, activation = 'relu')(x)
x = GlobalAveragePooling2D()(x)
outputs = Dense(2, activation = 'sigmoid')(x)

model2 = Model(inputs, outputs)

model2.compile(loss = 'binary_crossentropy',
               optimizer = tf.keras.optimizers.Adam(),
               metrics = ['accuracy'])

model2.summary()

history2 = model2.fit(train_data, epochs = 5, validation_data = test_data)

model2.evaluate(validation_data)

y_preds = model2.predict(validation_data).argmax(axis = 1)

print(classification_report(y_preds, y_labels))

"""## **ResNet50**"""

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Commented out IPython magic to ensure Python compatibility.
!unzip /content/drive/MyDrive/archive69.zip
# %ls

IMG_SHAPE = (224, 224, 3)
BATCH_SIZE = 32
TRAIN_DIR = "/content/train"
TEST_DIR = "/content/test"
VAL_DIR = "/content/valid"

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)

for layer in base_model.layers:
    layer.trainable = False

x = layers.Flatten()(base_model.output)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(2, activation='sigmoid')(x)

model_resnet50 = Model(base_model.input, x)

model_resnet50.compile(optimizer=Adam(learning_rate=0.0001),
                       loss='binary_crossentropy',
                       metrics=['accuracy'])

model_resnet50.summary()

# Create data generators
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=(224, 224),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=(224, 224),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    VAL_DIR,
    target_size=(224, 224),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

# Train the model
history_resnet50 = model_resnet50.fit(
    train_generator,
    epochs=5,
    validation_data=test_generator
)

history_resnet50 = model_resnet50.fit(
    train_generator,
    epochs=5,
    validation_data=test_generator
)

model_resnet50.evaluate(validation_generator)

y_preds_resnet50 = model_resnet50.predict(validation_generator).argmax(axis=1)
y_labels_resnet50 = validation_generator.classes

from sklearn.metrics import classification_report
print(classification_report(y_labels_resnet50, y_preds_resnet50))

"""## **ResNet18**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
from tqdm.notebook import tqdm
from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models, transforms, datasets
from torch.optim.lr_scheduler import ReduceLROnPlateau

torch.manual_seed(42)
np.random.seed(42)

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation(30),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_path = "/content/train"
valid_path = "/content/valid"
test_path = "/content/test"

# Commented out IPython magic to ensure Python compatibility.
!unzip /content/drive/MyDrive/archive69.zip
# %ls

train_dataset = datasets.ImageFolder(train_path, transform=transform)
valid_dataset = datasets.ImageFolder(valid_path, transform=transform)
test_dataset = datasets.ImageFolder(test_path, transform=transform)

batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

def visualize_samples(loader, class_labels):
    figure = plt.figure(figsize=(12, 12))
    cols, rows = 4, 4
    for i in range(1, cols * rows + 1):
        sample_idx = np.random.randint(len(loader.dataset))
        img, label = loader.dataset[sample_idx]
        figure.add_subplot(rows, cols, i)
        plt.title(class_labels[label])
        plt.axis("off")
        img_np = img.numpy().transpose((1, 2, 0))
        img_valid_range = np.clip(img_np, 0, 1)
        plt.imshow(img_valid_range)
    plt.show()

class_labels = {0: 'Diabetic Retinopathy', 1: 'No Diabetic Retinopathy'}
visualize_samples(train_loader, class_labels)

class TransferNet(nn.Module):
    def __init__(self, num_classes=2):
        super(TransferNet, self).__init__()
        resnet = models.resnet18(pretrained=True)
        # Remove the last fully connected layer
        self.features = nn.Sequential(*list(resnet.children())[:-1])
        # Add custom fully connected layer
        self.fc = nn.Linear(resnet.fc.in_features, num_classes)

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

transfer_model = TransferNet()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
transfer_model = transfer_model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(transfer_model.parameters(), lr=1e-4)
lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)

def train_transfer_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=20):
    for epoch in tqdm(range(num_epochs), desc="Epochs"):
        model.train()
        running_loss = 0.0
        for inputs, labels in tqdm(train_loader, desc="Training", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        # Validation
        model.eval()
        val_loss = 0.0
        correct_preds = 0
        total_samples = 0
        with torch.no_grad():
            for inputs, labels in tqdm(valid_loader, desc="Validation", leave=False):
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item()

                _, preds = torch.max(outputs, 1)
                correct_preds += torch.sum(preds == labels.data)
                total_samples += labels.size(0)

        avg_train_loss = running_loss / len(train_loader.dataset)
        avg_val_loss = val_loss / len(valid_loader.dataset)
        accuracy = correct_preds.double() / total_samples

        scheduler.step(avg_val_loss)

        print(f'Epoch [{epoch + 1}/{num_epochs}], '
              f'Training Loss: {avg_train_loss:.4f}, '
              f'Validation Loss: {avg_val_loss:.4f}, '
              f'Accuracy: {accuracy:.4f}')

def plot_confusion_matrix(y_true, y_pred, classes):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 8))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

train_transfer_model(transfer_model, train_loader, valid_loader, criterion, optimizer, lr_scheduler, num_epochs=10)

def plot_confusion_matrix(y_true, y_pred, classes):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 8))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

# Evaluate the transfer model on the test set
def evaluate_transfer_model(model, test_loader):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    return all_labels, all_preds

# Plot confusion matrix
class_labels = {0: 'Diabetic Retinopathy', 1: 'No Diabetic Retinopathy'}
y_true, y_pred = evaluate_transfer_model(transfer_model, test_loader)
plot_confusion_matrix(y_true, y_pred, classes=list(class_labels.values()))

# Save the transfer model
torch.save(transfer_model.state_dict(), "transfer_model.pth")

# Load the saved transfer model
loaded_transfer_model = TransferNet()
loaded_transfer_model.load_state_dict(torch.load("transfer_model.pth"))
loaded_transfer_model.to(device)

# Make predictions on a sample image
def predict_single_image(model, image_path, transform):
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img = transform(img).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(img)
        probabilities = torch.softmax(output, dim=1)
        predicted_class = torch.argmax(probabilities, dim=1).item()
    return predicted_class, probabilities[0].cpu().numpy()

# Example prediction
image_path = "/content/test/DR/31cb39681f6a_png.rf.e654e0f889e95ac80d7c91b6a56e5c39.jpg"
predicted_class, probabilities = predict_single_image(loaded_transfer_model, image_path, transform)
class_name = class_labels[predicted_class]
print(f"Predicted class: {class_name}, Probabilities: {probabilities}")

def visualize_predicted_image(model, image_path, transform, class_labels):
    predicted_class, probabilities = predict_single_image(model, image_path, transform)
    class_name = class_labels[predicted_class]

    # Load and display the image
    img = Image.open(image_path).convert('RGB')
    plt.imshow(img)
    plt.title(f'Predicted Class: {class_name}\nProbabilities: {probabilities}')
    plt.axis('off')
    plt.show()

# Example usage:
image_path = "/content/test/DR/31cb39681f6a_png.rf.e654e0f889e95ac80d7c91b6a56e5c39.jpg"
visualize_predicted_image(loaded_transfer_model, image_path, transform, class_labels)

"""## **VGG16**"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras import layers, Model

# Commented out IPython magic to ensure Python compatibility.
!unzip /content/drive/MyDrive/archive69.zip
# %ls

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

for layer in base_model.layers:
    layer.trainable = False

inputs = Input(shape=(224, 224, 3))
x = preprocess_input(inputs)  # Preprocess input according to VGG16 requirements
x = base_model(x, training=False)
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
outputs = Dense(2, activation='sigmoid')(x)  # Assuming 2 classes

model_vgg16 = Model(inputs, outputs)

model_vgg16.compile(optimizer='adam',
                    loss='binary_crossentropy',
                    metrics=['accuracy'])

model_vgg16.summary()

history_vgg16 = model_vgg16.fit(train_data, epochs=5, validation_data=test_data)

model_vgg16.evaluate(validation_data)

y_preds_vgg16 = model_vgg16.predict(validation_data).argmax(axis=1)
print(classification_report(y_preds_vgg16, y_labels))

"""##  **LOGISTIC REGRESSION**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense

model_lr = Sequential([
    Flatten(input_shape=IMG_SHAPE + (3, )),
    Dense(2, activation='sigmoid')
])

model_lr.compile(loss='binary_crossentropy',
                 optimizer=tf.keras.optimizers.Adam(),
                 metrics=['accuracy'])

model_lr.summary()

history_lr = model_lr.fit(train_data, epochs=5, validation_data=test_data)

model_lr.evaluate(validation_data)

y_preds_lr = model_lr.predict(validation_data).argmax(axis=1)
print(classification_report(y_labels, y_preds_lr))

"""## **SVM**"""

from sklearn import svm
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

def reshape_images(dataset):
    images = []
    labels = []
    for img_batch, label_batch in dataset:
        for i in range(len(img_batch)):
            images.append(img_batch[i].numpy().reshape(-1))
            labels.append(label_batch[i].numpy().argmax())
    return np.array(images), np.array(labels)

X_train, y_train = reshape_images(train_data)
X_test, y_test = reshape_images(test_data)
X_validation, y_validation = reshape_images(validation_data)

svm_model = make_pipeline(StandardScaler(), svm.SVC(C=1.0, kernel='rbf', gamma='auto'))

svm_model.fit(X_train, y_train)

y_preds_svm = svm_model.predict(X_validation)

print(classification_report(y_validation, y_preds_svm))

"""## **MOBILE NET**"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

base_model = MobileNetV2(input_shape=IMG_SHAPE + (3,), include_top=False, weights='imagenet')

base_model.trainable = False

inputs = Input(shape=IMG_SHAPE + (3,))
x = preprocess_input(inputs)  # Preprocess input according to MobileNetV2 requirements
x = base_model(x, training=False)
x = GlobalAveragePooling2D()(x)
outputs = Dense(2, activation='sigmoid')(x)

model_mobilenet = Model(inputs, outputs)

model_mobilenet.compile(loss='binary_crossentropy',
                        optimizer=tf.keras.optimizers.Adam(),
                        metrics=['accuracy'])

model_mobilenet.summary()

history_mobilenet = model_mobilenet.fit(train_data, epochs=5, validation_data=test_data)

model_mobilenet.evaluate(validation_data)

y_preds_mobilenet = model_mobilenet.predict(validation_data).argmax(axis=1)
print(classification_report(y_preds_mobilenet, y_labels))